<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Live Two-Way Voice Chat</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      background: #fafafa;
      font-family: sans-serif;
    }
    button {
      font-size: 1.5rem;
      padding: 1rem 2rem;
      margin: 0.5rem;
      border: none;
      border-radius: 8px;
      background: #0069ff;
      color: white;
      cursor: pointer;
    }
    button:disabled {
      background: #888;
    }
    #status {
      margin-top: 1rem;
    }
  </style>
  <script type="module">
    import { createChatStream, createAudioStream }
      from 'https://cdn.jsdelivr.net/npm/openai-realtime@0.1.0/dist/index.js';

    let socket, recorder, micStream;

    async function startLiveChat() {
      // ask for your API key each session
      const apiKey = prompt("Enter your OpenAI API key:");
      if (!apiKey) {
        alert("API key is required.");
        return;
      }

      const btn = document.getElementById('connect');
      const status = document.getElementById('status');
      btn.disabled = true;
      status.textContent = 'üéôÔ∏è Initializing‚Ä¶';

      // 1. get mic permission
      try {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        alert("Microphone access is required.");
        btn.disabled = false;
        return;
      }

      // 2. connect to OpenAI realtime
      status.textContent = 'üîó Connecting‚Ä¶';
      try {
        socket = await createChatStream({ apiKey, model: 'gpt-4o-realtime' });
      } catch (err) {
        console.error(err);
        alert("Could not connect to OpenAI.");
        btn.disabled = false;
        return;
      }

      status.textContent = 'üéß Live‚Äîspeak now';

      // 3. play incoming audio chunks immediately
      createAudioStream(socket, {
        onAudio: (chunk) => {
          const ctx = new AudioContext();
          ctx.decodeAudioData(chunk.buffer).then(buf => {
            const src = ctx.createBufferSource();
            src.buffer = buf;
            src.connect(ctx.destination);
            src.start();
          });
        }
      });

      // 4. capture and send mic audio in small slices
      recorder = new MediaRecorder(micStream, { mimeType: 'audio/webm;codecs=opus' });
      recorder.addEventListener('dataavailable', (e) => {
        if (e.data.size > 0 && socket.readyState === WebSocket.OPEN) {
          socket.send(e.data);
        }
      });
      recorder.start(200); // send every 200ms

      // 5. cleanup on close
      socket.addEventListener('close', () => {
        recorder.stop();
        micStream.getTracks().forEach(t => t.stop());
        status.textContent = 'üîå Disconnected';
        btn.disabled = false;
      });
    }
  </script>
</head>
<body>
  <button id="connect" onclick="startLiveChat()">Connect & Talk</button>
  <div id="status">‚ñ∂Ô∏è Tap to start live chat</div>
</body>
</html>
