<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Live Two-Way Voice Chat</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      background: #fafafa;
      font-family: sans-serif;
    }
    #connect {
      font-size: 1.5rem;
      padding: 1rem 2rem;
      border: none;
      border-radius: 8px;
      background: #0069ff;
      color: white;
      cursor: pointer;
    }
    #connect:disabled {
      background: #888;
    }
    #status {
      margin-top: 1rem;
    }
  </style>
</head>
<body>
  <button id="connect">Connect & Talk</button>
  <div id="status">‚ñ∂Ô∏è Tap to start live chat</div>

  <script type="module">
    // ** ALERT ON LOAD **
    alert("‚è±Ô∏è Script loaded");

    import { createChatStream, createAudioStream }
      from 'https://cdn.jsdelivr.net/npm/openai-realtime@0.1.0/dist/index.js';

    // Expose our main function
    async function startLiveChat() {
      alert("üîä Button clicked");

      const btn = document.getElementById('connect');
      const status = document.getElementById('status');

      // 1) Prompt for API key
      const apiKey = prompt("Enter your OpenAI API key:");
      if (!apiKey) {
        alert("API key is required.");
        return;
      }

      btn.disabled = true;
      status.textContent = 'üéôÔ∏è Initializing‚Ä¶';

      // 2) Mic permission
      let micStream;
      try {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch {
        alert("Microphone access denied.");
        btn.disabled = false;
        return;
      }

      // 3) Connect to OpenAI Realtime
      status.textContent = 'üîó Connecting‚Ä¶';
      let socket;
      try {
        socket = await createChatStream({ apiKey, model: 'gpt-4o-realtime' });
      } catch (err) {
        console.error(err);
        alert("Failed to connect to OpenAI.");
        btn.disabled = false;
        return;
      }

      status.textContent = 'üéß Live‚Äîspeak now';

      // 4) Play incoming audio immediately
      createAudioStream(socket, {
        onAudio: (chunk) => {
          const ctx = new AudioContext();
          ctx.decodeAudioData(chunk.buffer).then(buf => {
            const src = ctx.createBufferSource();
            src.buffer = buf;
            src.connect(ctx.destination);
            src.start();
          });
        }
      });

      // 5) Send mic audio in slices
      const recorder = new MediaRecorder(micStream, { mimeType: 'audio/webm;codecs=opus' });
      recorder.addEventListener('dataavailable', (e) => {
        if (e.data.size > 0 && socket.readyState === WebSocket.OPEN) {
          socket.send(e.data);
        }
      });
      recorder.start(200);

      // 6) Cleanup on close
      socket.addEventListener('close', () => {
        recorder.stop();
        micStream.getTracks().forEach(t => t.stop());
        status.textContent = 'üîå Disconnected';
        btn.disabled = false;
      });
    }

    // Attach click handler
    document.getElementById('connect').addEventListener('click', startLiveChat);
  </script>
</body>
</html>
