<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Live Voice Chat (OpenAI Realtime)</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      background: #fafafa;
      font-family: sans-serif;
    }
    button {
      font-size: 1.25rem;
      padding: 0.75rem 1.5rem;
      margin: 0.5rem;
      border: none;
      border-radius: 6px;
      background: #0069ff;
      color: white;
      cursor: pointer;
    }
    button:disabled {
      background: #888;
    }
    #status {
      margin-top: 1rem;
    }
  </style>
  <script type="module">
    import { createChatStream, createAudioStream } from 'https://cdn.jsdelivr.net/npm/openai-realtime@0.1.0/dist/index.js';

    let socket, recorder, micStream;

    async function startLiveChat() {
      // Prompt for API key each session (never saved in code)
      const apiKey = prompt("Enter your OpenAI API key:");
      if (!apiKey) {
        alert("API key is required.");
        return;
      }

      const status = document.getElementById('status');
      const btn = document.getElementById('connect');
      btn.disabled = true;
      status.textContent = 'üîó Connecting‚Ä¶';

      // 1. Microphone access
      try {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (err) {
        alert("Microphone access denied.");
        btn.disabled = false;
        return;
      }

      // 2. OpenAI realtime connection
      try {
        socket = await createChatStream({
          apiKey,
          model: 'gpt-4o-realtime'
        });
      } catch (err) {
        console.error(err);
        alert("Failed to connect to OpenAI.");
        btn.disabled = false;
        return;
      }

      status.textContent = 'üéß Live‚Äîspeak now';

      // 3. Play incoming audio chunks immediately
      createAudioStream(socket, {
        onAudio: (chunk) => {
          const ctx = new AudioContext();
          ctx.decodeAudioData(chunk.buffer).then(buffer => {
            const src = ctx.createBufferSource();
            src.buffer = buffer;
            src.connect(ctx.destination);
            src.start();
          });
        }
      });

      // 4. Send mic audio in small chunks
      recorder = new MediaRecorder(micStream, { mimeType: 'audio/webm;codecs=opus' });
      recorder.addEventListener('dataavailable', (e) => {
        if (e.data.size && socket.readyState === WebSocket.OPEN) {
          socket.send(e.data);
        }
      });
      recorder.start(200);  // send every 200ms

      // 5. Handle end of session
      socket.addEventListener('close', () => {
        recorder.stop();
        micStream.getTracks().forEach(t => t.stop());
        status.textContent = 'üîå Disconnected';
        btn.disabled = false;
      });
    }
  </script>
</head>
<body>
  <button id="connect" onclick="startLiveChat()">Connect & Talk</button>
  <div id="status">‚ñ∂Ô∏è Tap to connect</div>
</body>
</html>
